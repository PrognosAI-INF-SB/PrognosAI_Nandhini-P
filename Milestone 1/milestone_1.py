# -*- coding: utf-8 -*-
"""milestone 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HTNrPiTOjcyzDl3THv9lwhObOn5I7qMd
"""

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

def load_and_clean(csv_path, time_col=None):
    print("Loading dataset...")
    df = pd.read_csv(csv_path)
    if not time_col:
        # infer time column
        candidates = [c for c in df.columns if 'time' in c.lower()]
        time_col = candidates[0] if candidates else df.columns[0]
    df = df.sort_values(by=time_col).reset_index(drop=True)
    print(f"Dataset loaded with {len(df)} rows and columns: {list(df.columns)}")

    # Check for missing values
    total_missing = df.isnull().sum().sum()
    print(f"Total missing values before imputation: {total_missing}")
    if total_missing > 0:
        imputer = SimpleImputer(strategy='median')
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        df[numeric_cols] = imputer.fit_transform(df[numeric_cols])
        print("Missing values imputed using median strategy.")
    else:
        print("No missing values found.")

    return df, time_col

def calculate_rul(df, time_col, cap=None):
    n = len(df)
    rul = np.arange(n-1, -1, -1)
    if cap:
        rul = np.minimum(rul, cap)
    df['RUL'] = rul
    print(f"RUL calculated with cap={cap}")
    print("Sample RUL values (first 5):", df['RUL'].head().tolist())
    return df

def generate_rolling_windows(df, feature_cols, label_col='RUL', window_size=50, stride=1):
    X, y = [], []
    n = len(df)
    print(f"Generating rolling windows with size={window_size}, stride={stride}...")
    for start in range(0, n - window_size + 1, stride):
        end = start + window_size
        X.append(df.loc[start:end-1, feature_cols].values)
        y.append(df.loc[end-1, label_col])
    X = np.array(X)
    y = np.array(y)
    print(f"Generated {len(X)} sequences.")
    # Verification print
    print("\nSample Sequence Feature Window (first sequence):")
    print(X[0])
    print("\nCorresponding RUL label for first sequence:", y[0])
    return X, y

def batch_process_and_print(df, time_col, sensor_cols, batch_size=500):
    n = len(df)
    print(f"\nStarting batch processing with batch size={batch_size}...")
    for start in range(0, n, batch_size):
        end = min(start + batch_size, n)
        batch = df.iloc[start:end]
        print(f"\nBatch rows: {start} to {end - 1}")

        # Basic batch stats
        print(f"Mean sensor values:")
        print(batch[sensor_cols].mean())
        print(f"RUL range: {batch['RUL'].min()} to {batch['RUL'].max()}")

def main():
    csv_path = "sensor_data.csv"  # path to your dataset
    df, time_col = load_and_clean(csv_path)

    # Infer sensor columns for feature engineering
    sensor_cols = [c for c in df.columns if c != time_col and pd.api.types.is_numeric_dtype(df[c])]
    print(f"Sensor columns inferred for feature engineering: {sensor_cols}")

    df = calculate_rul(df, time_col=time_col, cap=125)

    X, y = generate_rolling_windows(df, feature_cols=sensor_cols, label_col='RUL', window_size=50)

    batch_process_and_print(df, time_col, sensor_cols, batch_size=500)

    print("\nMilestone 1 processing complete. All outputs are printed above.")

if __name__ == "__main__":
    main()